from selenium.webdriver.firefox.options import Options
from selenium.webdriver.firefox.firefox_profile import FirefoxProfile
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait # подгрузка метода ожидания загрузки страницы
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains # реализация прокрутки страницы к необходимому элементу

import requests
from bs4 import BeautifulSoup
import urllib.parse
from datetime import datetime, time, timedelta
import time
import re
import json
from urllib.parse import urljoin


from selenium import webdriver
import time

# Настройки параметров ссесии браузера
option = Options()
option.add_argument("start-maximized")

option = webdriver.FirefoxOptions()

# создаю окно браузера и передаю ему параметры
# browser = webdriver.Chrome(options=option)

browser = webdriver.Firefox(options=option)
browser.get('https://www.foroffice.ru/') # вызываю страницу сайта промышленного оборудования в браузере



# wait = WebDriverWait(browser, 30)
# Ввожу информацию в строку поиска и кликаю на "лупу" для осуществления поиска по сайту
input_web = browser.find_element(By.ID, "__BVID__17")
input_web.send_keys('резак')
element = WebDriverWait(browser, 20).until(EC.element_to_be_clickable((By.XPATH, '//button[@class="btn btn-blue search-button"]')))
element.click()

# Получаю url текущей страница
current_url = str(browser.current_url).strip()
# current_url = "https://www.foroffice.ru/search/search_results.php?q=%F0%E5%E7%E0%EA"

# Так как ссылка на станицу от Selenium отличается от ссылки которую получаю при ручном поиске, и ссылка от Seleium не парсится, но эта ссылка содержит кодировку котурую можно применить для создания ссылки которую можно пропарсить
print('URL:',current_url, sep='\n')
print()
find_key_word = current_url.find('q=')
url =  f'https://www.foroffice.ru/products/search/?' + current_url[find_key_word:]
fake_user = "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:133.0) Gecko/20100101 Firefox/133.0"# создаю фейкового юзера
response = requests.get(url, headers = {'User-Agent' : fake_user}) # Получаю get запрос по API

# Парсинг HTML-содержимого веб-страницы с помощью Beautiful Soup
soup = BeautifulSoup(response.content, 'html.parser')
release_links = []
result_dict = {} # Словарь с информацией о товаре

# Собираю информацию о товаре с первой странице
for link, info in zip(soup.find_all('div', ('class', "center col")), soup.find_all('div', ('class', 'right col'))):
    try:
        find_link= urljoin('https://www.foroffice.ru/', link.find('a').get('href')) # ссылка на
        name_item = link.find('a').text.strip() # наименование товара

        price = info.find('span').text.strip().split("\n") # вывожу стоимость товара и валюту в список
        print(name_item, price, find_link)

        result_dict[find_link] = [name_item, price]
    except:
        release_links.append('None')


pprint(result_dict)
input()
browser.quit()
